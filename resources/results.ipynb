{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9bca04-46c4-4442-b20d-d3c8ba7e0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model and print out the statistics yaml\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "import yaml\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from mymodel import init_my_model\n",
    "\n",
    "\n",
    "model = init_my_model() \n",
    "min_max_yaml = yaml.safe_load(open(\"min_max.yaml\", \"r\"))\n",
    "config = json.load(open(\"config.json\", \"r\"))\n",
    "stats = yaml.safe_load(open(\"stats.yaml\", \"r\"))\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model_name = model.__class__.__name__\n",
    "num_layers = len(list(model.net.children()))\n",
    "num_epochs = stats[\"epochs\"]\n",
    "best_train_loss = stats[\"best_train_loss\"]\n",
    "best_test_loss = stats[\"best_test_loss\"]\n",
    "best_val_loss = stats[\"best_val_loss\"]\n",
    "\n",
    "mae_u_train = stats[\"metrics\"][\"train\"][\"u\"][\"mae\"]\n",
    "mae_v_train = stats[\"metrics\"][\"train\"][\"v\"][\"mae\"]\n",
    "\n",
    "mae_u_test = stats[\"metrics\"][\"test\"][\"u\"][\"mae\"]\n",
    "mae_v_test = stats[\"metrics\"][\"test\"][\"v\"][\"mae\"]\n",
    "\n",
    "mae_u_val = stats[\"metrics\"][\"validation\"][\"u\"][\"mae\"]\n",
    "mae_v_val = stats[\"metrics\"][\"validation\"][\"v\"][\"mae\"]\n",
    "\n",
    "rmse_u_train = stats['metrics']['train']['u']['rmse']\n",
    "rmse_v_train = stats['metrics']['train']['v']['rmse']\n",
    "\n",
    "rmse_u_test = stats['metrics']['test']['u']['rmse']\n",
    "rmse_v_test = stats['metrics']['test']['v']['rmse']\n",
    "\n",
    "rmse_u_val = stats['metrics']['validation']['u']['rmse']\n",
    "rmse_v_val = stats['metrics']['validation']['v']['rmse']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de594ba4-66ca-460d-8f4c-057286f4bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = \"# Model Architecture\\n\"\n",
    "md_text += f\"The following section describes the architecture of the {model_name} used for the submission. \"\n",
    "md_text += f\"The {model_name} has a total number of {total_params} parameters \"\n",
    "md_text += f\"with {trainable_params} trainable parameters. \"\n",
    "md_text += f\"It consists of {num_layers} layers. \"\n",
    "md_text += \"The layers are structured as follows:\\n\\n\"\n",
    "md_text += \"| Index | Layer Type | Details |\\n\"\n",
    "md_text += \"| :--- | :--- | :--- |\\n\"\n",
    "\n",
    "for i, layer in enumerate(model.net.children()):\n",
    "    layer_type = layer.__class__.__name__\n",
    "    \n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        details = f\"In: {layer.in_channels}, Out: {layer.out_channels}, Kernel: {layer.kernel_size[0]}x{layer.kernel_size[1]}\"\n",
    "    elif isinstance(layer, nn.LeakyReLU):\n",
    "        details = f\"Negative Slope: {layer.negative_slope}\"\n",
    "    else:\n",
    "        details = \"---\"\n",
    "        \n",
    "    md_text += f\"| {i} | {layer_type} | {details} |\\n\"\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc0bd4c-89a9-4bcb-b1e6-1ed8c3000393",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = \"This was the configuration used to initialize the model and load the data:\\n\\n\"\n",
    "md_text += \"| Parameter | Value |\\n\"\n",
    "md_text += \"| :--- | :--- |\\n\"\n",
    "\n",
    "for k, v in config.items():\n",
    "    display_key = k.replace(\"_\", \" \").title()\n",
    "    md_text += f\"| {display_key} | {v} |\\n\"\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551d818-fbd2-4686-8d29-0d0147cf00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dict_to_md(d, level=0):\n",
    "    lines = []\n",
    "    for k, v in d.items():\n",
    "        indent = \"  \" * level\n",
    "        if isinstance(v, dict) and v.get(\"min\") or v.get(\"max\"):\n",
    "            lines.append(f\"{indent}* **{k.capitalize()}**: From {v['min']:.4f} to {v['max']:.4f}\")\n",
    "        elif isinstance(v, dict):\n",
    "            lines.append(f\"{indent}* **{k.capitalize()}**:\")\n",
    "            lines.extend(format_dict_to_md(v, level + 1))\n",
    "        else:\n",
    "            lines.append(f\"{indent}* **{k}**: {v}\")\n",
    "    return lines\n",
    "\n",
    "md_text = \"The input data was then normalized between 0 and 1 based on those ranges:\\n\\n\"\n",
    "md_text += \"\\n\".join(format_dict_to_md(min_max_yaml))\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9301fe-447b-424a-8ecc-1efb2ffb7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = \"# Evaluation\\n\"\n",
    "md_text += \"## Loss Graphs\\n\"\n",
    "md_text += f\"The following figure shows the training, validation and test loss over the {num_epochs} epochs the model was trained on.\\n\\n\"\n",
    "md_text += \"![Train and test losses](losses.png)\\n\\n\"\n",
    "md_text += f\"The best losses archieved while training where {best_train_loss:.4g} on the training data, \"\n",
    "md_text += f\"{best_test_loss:.4g} on the test data and {best_val_loss:.4g} on the validation data.\\n\\n\"\n",
    "md_text += \"## Performance Metrics\\n\"\n",
    "md_text += \"The table below summarizes the error metrics for the velocity components u and v across all data splits.\\n\\n\"\n",
    "md_text += \"| Metric | Field | Training | Test | Validation |\\n\"\n",
    "md_text += \"| :--- | :--- | :--- | :--- | :--- |\\n\"\n",
    "md_text += f\"| **Mean absolute error** | u | {mae_u_train:.3g} | {mae_u_test:.3g} | {mae_u_val:.3g} |\\n\"\n",
    "md_text += f\"| | v | {mae_v_train:.3g} | {mae_v_test:.3g} | {mae_v_val:.3g} |\\n\"\n",
    "md_text += f\"| **Root mean square error** | u | {rmse_u_train:.3g} | {rmse_u_test:.3g} | {rmse_u_val:.3g} |\\n\"\n",
    "md_text += f\"| | v | {rmse_v_train:.3g} | {rmse_v_test:.3g} | {rmse_v_val:.3g} |\\n\"\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d7bbc-92d2-4d30-bc8b-57c397b8fac2",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "## Interpolation\n",
    "\n",
    "Sample data point predictions and comparisons to their labels (and visualization of vector fields)\n",
    "\n",
    "## Extrapolation\n",
    "\n",
    "To see how well the model generalizes, the following section should contain three out-of-distribution test samples."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Julian Schmoll, Fabio Tucciarone, Benedikt RÃ¶sch"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "title": "Model Evaluation"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
