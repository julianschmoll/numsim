{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9bca04-46c4-4442-b20d-d3c8ba7e0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from mymodel import init_my_model\n",
    "\n",
    "\n",
    "model = init_my_model() \n",
    "min_max_yaml = yaml.safe_load(open(\"min_max.yaml\", \"r\"))\n",
    "config = json.load(open(\"config.json\", \"r\"))\n",
    "stats = yaml.safe_load(open(\"stats.yaml\", \"r\"))\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model_name = model.__class__.__name__\n",
    "num_layers = len(list(model.net.children()))\n",
    "num_epochs = stats[\"epochs\"]\n",
    "best_train_loss = stats[\"best_train_loss\"]\n",
    "best_test_loss = stats[\"best_test_loss\"]\n",
    "best_val_loss = stats[\"best_val_loss\"]\n",
    "\n",
    "mae_u_train = stats[\"metrics\"][\"train\"][\"u\"][\"mae\"]\n",
    "mae_v_train = stats[\"metrics\"][\"train\"][\"v\"][\"mae\"]\n",
    "\n",
    "mae_u_test = stats[\"metrics\"][\"test\"][\"u\"][\"mae\"]\n",
    "mae_v_test = stats[\"metrics\"][\"test\"][\"v\"][\"mae\"]\n",
    "\n",
    "mae_u_val = stats[\"metrics\"][\"validation\"][\"u\"][\"mae\"]\n",
    "mae_v_val = stats[\"metrics\"][\"validation\"][\"v\"][\"mae\"]\n",
    "\n",
    "rmse_u_train = stats['metrics']['train']['u']['rmse']\n",
    "rmse_v_train = stats['metrics']['train']['v']['rmse']\n",
    "\n",
    "rmse_u_test = stats['metrics']['test']['u']['rmse']\n",
    "rmse_v_test = stats['metrics']['test']['v']['rmse']\n",
    "\n",
    "rmse_u_val = stats['metrics']['validation']['u']['rmse']\n",
    "rmse_v_val = stats['metrics']['validation']['v']['rmse']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de594ba4-66ca-460d-8f4c-057286f4bc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "_This document was generated automatically after training._\n",
       "\n",
       "# Model Architecture\n",
       "The following section describes the architecture of the FluidCNN used for the submission. The FluidCNN has a total number of 98802 parameters with 98802 trainable parameters. It consists of 9 layers. The layers are structured as follows:\n",
       "\n",
       "| Layer Type | Details |\n",
       "| :--- | :--- |\n",
       "| Conv2d | In: 1, Out: 16, Kernel: 11x11, Stride: 1x1, Padding: same |\n",
       "| ELU | Alpha: 1.0 |\n",
       "| Conv2d | In: 16, Out: 16, Kernel: 11x11, Stride: 1x1, Padding: same |\n",
       "| ELU | Alpha: 1.0 |\n",
       "| Conv2d | In: 16, Out: 16, Kernel: 11x11, Stride: 1x1, Padding: same |\n",
       "| ELU | Alpha: 1.0 |\n",
       "| Conv2d | In: 16, Out: 16, Kernel: 11x11, Stride: 1x1, Padding: same |\n",
       "| ELU | Alpha: 1.0 |\n",
       "| Conv2d | In: 16, Out: 2, Kernel: 11x11, Stride: 1x1, Padding: same |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "md_text = \"_This document was generated automatically after training._\\n\\n\"\n",
    "md_text += \"# Model Architecture\\n\"\n",
    "md_text += f\"The following section describes the architecture of the {model_name} used for the submission. \"\n",
    "md_text += f\"The {model_name} has a total number of {total_params} parameters \"\n",
    "md_text += f\"with {trainable_params} trainable parameters. \"\n",
    "md_text += f\"It consists of {num_layers} layers. \"\n",
    "md_text += \"The layers are structured as follows:\\n\\n\"\n",
    "md_text += \"| Layer Type | Details |\\n\"\n",
    "md_text += \"| :--- | :--- |\\n\"\n",
    "\n",
    "def get_details(layer):\n",
    "    # This might be very incomplete :)\n",
    "    attr_map = {\n",
    "        'in_channels': 'In', 'out_channels': 'Out',\n",
    "        'in_features': 'In', 'out_features': 'Out',\n",
    "        'kernel_size': 'Kernel', 'stride': 'Stride', 'padding': 'Padding',\n",
    "        'p': 'Drop', 'negative_slope': 'Slope', 'alpha': 'Alpha',\n",
    "        'lambd': 'Lambda',\n",
    "        'beta': 'Beta',               # Softplus, Swish\n",
    "        'threshold': 'Threshold',     # Hardshrink, Softshrink, Threshold\n",
    "        'value': 'Value',             # Threshold\n",
    "        'min_val': 'Min',             # Hardtanh\n",
    "        'max_val': 'Max',             # Hardtanh\n",
    "        'lower': 'Lower',             # RReLU\n",
    "        'upper': 'Upper',             # RReLU\n",
    "        'approximate': 'Approximate', # GELU\n",
    "        'num_parameters': 'Params'    # PReLU\n",
    "    }\n",
    "    \n",
    "    parts = []\n",
    "    for attr, label in attr_map.items():\n",
    "        if hasattr(layer, attr):\n",
    "            val = getattr(layer, attr)\n",
    "            # Format tuples like (3, 3) into \"3x3\"\n",
    "            if isinstance(val, (tuple, list)):\n",
    "                val = \"x\".join(map(str, val))\n",
    "            parts.append(f\"{label}: {val}\")\n",
    "            \n",
    "    return \", \".join(parts) if parts else \"---\"\n",
    "\n",
    "for layer in model.net.children():\n",
    "    layer_type = layer.__class__.__name__\n",
    "    details = get_details(layer)\n",
    "    md_text += f\"| {layer_type} | {details} |\\n\"\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc0bd4c-89a9-4bcb-b1e6-1ed8c3000393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This was the configuration used to initialize the model and load the data:\n",
       "\n",
       "| Parameter | Value | Explanation |\n",
       "| :--- | :--- | :--- |\n",
       "| Activation | ELU | Activation function. |\n",
       "| Batch Size | 4 | Training data in one iteration. |\n",
       "| Criterion | MSELoss | Loss function objective. |\n",
       "| Early Stopping Patience | 300 | Epochs to wait for improvement. |\n",
       "| Epochs | 50 | Total Number of Epochs. |\n",
       "| Hidden Channels | 16 | Depth of the Network. |\n",
       "| In Channels | 1 | Input feature map depth. |\n",
       "| Kernel Size | 11 | The size of the kernel. |\n",
       "| Learning Rate | 5e-05 | Optimizer step size. |\n",
       "| Num Hidden Layers | 3 | Network depth. |\n",
       "| Out Channels | 2 | Number of learned filters. |\n",
       "| Output Activation | None | Final layer activation. |\n",
       "| Padding Mode | zeros | Boundary condition strategy. |\n",
       "| Random Seed | 1 | Torch Seed. |\n",
       "| Random Split | False | Wheter to split data randomly. |\n",
       "| Train Ratio | 0.6 | Training/Validation split proportion. |\n",
       "| Use Bias | True | Learnable additive offset. |\n",
       "| Use Early Stopping | True | Stop when model stops converging. |\n",
       "| Use Lr Scheduler | True | Dynamic LR adjustment per epoch. |\n",
       "| Weight Decay | 0.0001 | Regularization coefficient. |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mapping of keys to their ML explanations\n",
    "EXPLANATIONS = {\n",
    "    \"activation\": \"Activation function.\",\n",
    "    \"model\": \"Model Class Name.\",\n",
    "    \"train_ratio\": \"Training/Validation split proportion.\",\n",
    "    \"learning_rate\": \"Optimizer step size.\",\n",
    "    \"weight_decay\": \"Regularization coefficient.\",\n",
    "    \"use_lr_scheduler\": \"Dynamic LR adjustment per epoch.\",\n",
    "    \"use_early_stopping\": \"Stop when model stops converging.\",\n",
    "    \"early_stopping_patience\": \"Epochs to wait for improvement.\",\n",
    "    \"criterion\": \"Loss function objective.\",\n",
    "    \"batch_size\": \"Training data in one iteration.\",\n",
    "    \"epochs\": \"Total Number of Epochs.\",\n",
    "    \"num_hidden_layers\": \"Network depth.\",\n",
    "    \"kernel_size\": \"The size of the kernel.\",\n",
    "    \"in_channels\": \"Input feature map depth.\",\n",
    "    \"out_channels\": \"Number of learned filters.\",\n",
    "    \"hidden_channels\": \"Depth of the Network.\",\n",
    "    \"output_activation\": \"Final layer activation.\",\n",
    "    \"use_bias\": \"Learnable additive offset.\",\n",
    "    \"padding_mode\": \"Boundary condition strategy.\",\n",
    "    \"random_split\": \"Whether to split data randomly.\",\n",
    "    \"random_seed\": \"Torch Seed.\",\n",
    "}\n",
    "\n",
    "md_text = \"This was the configuration used to initialize the model and load the data:\\n\\n\"\n",
    "md_text += \"| Parameter | Value | Explanation |\\n\"\n",
    "md_text += \"| :--- | :--- | :--- |\\n\"\n",
    "\n",
    "for k, v in sorted(config.items()):\n",
    "    display_key = k.replace(\"_\", \" \").title()\n",
    "    explanation = EXPLANATIONS.get(k, \"---\")\n",
    "    md_text += f\"| {display_key} | {v} | {explanation} |\\n\"\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551d818-fbd2-4686-8d29-0d0147cf00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dict_to_md(d, level=0):\n",
    "    lines = []\n",
    "    for k, v in d.items():\n",
    "        indent = \"  \" * level\n",
    "        if isinstance(v, dict) and v.get(\"min\") or v.get(\"max\"):\n",
    "            lines.append(f\"{indent}* **{k.capitalize()}**: From {v['min']:.4f} to {v['max']:.4f}\")\n",
    "        elif isinstance(v, dict):\n",
    "            lines.append(f\"{indent}* **{k.capitalize()}**:\")\n",
    "            lines.extend(format_dict_to_md(v, level + 1))\n",
    "        else:\n",
    "            lines.append(f\"{indent}* **{k}**: {v}\")\n",
    "    return lines\n",
    "\n",
    "md_text = \"The input data was then normalized between 0 and 1 based on those ranges:\\n\\n\"\n",
    "md_text += \"\\n\".join(format_dict_to_md(min_max_yaml))\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9301fe-447b-424a-8ecc-1efb2ffb7fc3",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "md_text = \"# Evaluation\\n\"\n",
    "md_text += \"## Loss Graphs\\n\"\n",
    "md_text += f\"The following figure shows the training, validation and test loss over the {num_epochs} epochs the model was trained on.\\n\\n\"\n",
    "md_text += \"![Train and test losses](losses.png)\\n\\n\"\n",
    "md_text += f\"The best losses achieved during training (MSE on normalized data) were {best_train_loss:.4g} on the training data, \"\n",
    "md_text += f\"{best_test_loss:.4g} on the test data and {best_val_loss:.4g} on the validation data.\\n\\n\"\n",
    "md_text += \"## Performance Metrics\\n\"\n",
    "md_text += \"The table below summarizes the error metrics for the velocity components across all data splits on the denormalized fields (in original velocity units).\\n\\n\"\n",
    "md_text += \"| Metric | Field | Training | Test | Validation |\\n\"\n",
    "md_text += \"| :--- | :--- | :--- | :--- | :--- |\\n\"\n",
    "md_text += f\"| **Mean absolute error** | u | {mae_u_train:.3g} | {mae_u_test:.3g} | {mae_u_val:.3g} |\\n\"\n",
    "md_text += f\"| | v | {mae_v_train:.3g} | {mae_v_test:.3g} | {mae_v_val:.3g} |\\n\"\n",
    "md_text += f\"| **Root mean square error** | u | {rmse_u_train:.3g} | {rmse_u_test:.3g} | {rmse_u_val:.3g} |\\n\"\n",
    "md_text += f\"| | v | {rmse_v_train:.3g} | {rmse_v_test:.3g} | {rmse_v_val:.3g} |\\n\"\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aadded-247b-4d68-a9ce-16f1a4d5f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = Path(\"plots\") / \"interpolation\"\n",
    "\n",
    "md_text = \"# Predictions\\n\"\n",
    "md_text += \"We expect the model to perform better within the data range it was trained on (interpolation) \"\n",
    "md_text += \"and perform worse on data it has not seen yet (extrapolation). So we differentiate between those.\\n\\n\"\n",
    "md_text += \"## Interpolation\\n\\n\"\n",
    "\n",
    "error_plots = []\n",
    "quiver_plots = []\n",
    "prediction_plots = []\n",
    "\n",
    "number = len(sorted(plot_dir.iterdir()))\n",
    "md_text += f\"Below are {number} predictions within the data range the model was trained on.\\n\\n\"\n",
    "\n",
    "for plot_subdir in sorted(plot_dir.iterdir()):\n",
    "    for plot in reversed(sorted(plot_subdir.iterdir())):\n",
    "        if plot.is_file():\n",
    "            if \"prediction\" in plot.name and not \"quiver\" in plot.name:\n",
    "                continue\n",
    "            md_text += f\"![plot]({plot})\\n\\n\"     \n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f82b5-969d-43a1-a00a-eba3da1d8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = Path(\"plots\") / \"extrapolation\"\n",
    "error_plots = []\n",
    "quiver_plots = []\n",
    "prediction_plots = []\n",
    "\n",
    "md_text = \"# Extrapolation\\n\"\n",
    "md_text += \"The extrapolation section shows how good the model is at generalizing. We differentiate between three different extrapolations:\\n\\n\"\n",
    "md_text += \"1. Other positive flow speeds\\n\"\n",
    "md_text += \"2. Other resolutions\\n\"\n",
    "md_text += \"3. Negative flow speeds/Flow at another boundary\\n\\n\"\n",
    "md_text += \"We mostly care about the first and second case, because the third can be easily turned into the first by rotating/flipping the input.\\n\\n\"\n",
    "md_text += \"### Other Flow Speeds\\n\\n\"\n",
    "\n",
    "for plot_subdir in sorted(plot_dir.iterdir()):\n",
    "    if \"flow_speed\" in plot_subdir.name and not \"negative\" in plot_subdir.name:\n",
    "        for plot in sorted(plot_subdir.iterdir()):\n",
    "            md_text += f\"![plot]({plot})\\n\\n\"   \n",
    "\n",
    "md_text += \"### Other Resolutions\\n\\n\"\n",
    "\n",
    "for plot_subdir in sorted(plot_dir.iterdir()):\n",
    "    if \"resolution\" in plot_subdir.name:\n",
    "        for plot in sorted(plot_subdir.iterdir()):\n",
    "            md_text += f\"![plot]({plot})\\n\\n\"   \n",
    "\n",
    "md_text += \"### Other Boundaries\\n\\n\"\n",
    "\n",
    "for plot_subdir in sorted(plot_dir.iterdir()):\n",
    "    if \"negative\" in plot_subdir.name or \"boundary\" in plot_subdir.name:\n",
    "        for plot in sorted(plot_subdir.iterdir()):\n",
    "            md_text += f\"![plot]({plot})\\n\\n\"   \n",
    "\n",
    "display(Markdown(md_text))"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Julian Schmoll, Fabio Tucciarone, Benedikt RÃ¶sch"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "title": "Model Evaluation"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
