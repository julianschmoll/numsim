{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9bca04-46c4-4442-b20d-d3c8ba7e0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model and print out the statistics yaml\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "import yaml\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from mymodel import init_my_model\n",
    "\n",
    "\n",
    "model = init_my_model() \n",
    "min_max_yaml = yaml.safe_load(open(\"min_max.yaml\", \"r\"))\n",
    "config = json.load(open(\"config.json\", \"r\"))\n",
    "stats = yaml.safe_load(open(\"stats.yaml\", \"r\"))\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model_name = model.__class__.__name__\n",
    "num_layers = len(list(model.net.children()))\n",
    "num_epochs = stats[\"epochs\"]\n",
    "best_train_loss = stats[\"best_train_loss\"]\n",
    "best_test_loss = stats[\"best_test_loss\"]\n",
    "best_val_loss = stats[\"best_val_loss\"]\n",
    "\n",
    "mae_u_train = stats[\"metrics\"][\"train\"][\"u\"][\"mae\"]\n",
    "mae_v_train = stats[\"metrics\"][\"train\"][\"v\"][\"mae\"]\n",
    "\n",
    "mae_u_test = stats[\"metrics\"][\"test\"][\"u\"][\"mae\"]\n",
    "mae_v_test = stats[\"metrics\"][\"test\"][\"v\"][\"mae\"]\n",
    "\n",
    "mae_u_val = stats[\"metrics\"][\"validation\"][\"u\"][\"mae\"]\n",
    "mae_v_val = stats[\"metrics\"][\"validation\"][\"v\"][\"mae\"]\n",
    "\n",
    "rmse_u_train = stats['metrics']['train']['u']['rmse']\n",
    "rmse_v_train = stats['metrics']['train']['v']['rmse']\n",
    "\n",
    "rmse_u_test = stats['metrics']['test']['u']['rmse']\n",
    "rmse_v_test = stats['metrics']['test']['v']['rmse']\n",
    "\n",
    "rmse_u_val = stats['metrics']['validation']['u']['rmse']\n",
    "rmse_v_val = stats['metrics']['validation']['v']['rmse']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de594ba4-66ca-460d-8f4c-057286f4bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = \"# Model Architecture\\n\"\n",
    "md_text += f\"The following section describes the architecture of the {model_name} used for the submission. \"\n",
    "md_text += f\"The {model_name} has a total number of {total_params} parameters \"\n",
    "md_text += f\"with {trainable_params} trainable parameters. \"\n",
    "md_text += f\"It consists of {num_layers} layers. \"\n",
    "md_text += \"The layers are structured as follows:\\n\\n\"\n",
    "md_text += \"| Index | Layer Type | Details |\\n\"\n",
    "md_text += \"| :--- | :--- | :--- |\\n\"\n",
    "\n",
    "for i, layer in enumerate(model.net.children()):\n",
    "    layer_type = layer.__class__.__name__\n",
    "    \n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        details = f\"In: {layer.in_channels}, Out: {layer.out_channels}, Kernel: {layer.kernel_size[0]}x{layer.kernel_size[1]}\"\n",
    "    elif isinstance(layer, nn.LeakyReLU):\n",
    "        details = f\"Negative Slope: {layer.negative_slope}\"\n",
    "    else:\n",
    "        details = \"---\"\n",
    "        \n",
    "    md_text += f\"| {i} | {layer_type} | {details} |\\n\"\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc0bd4c-89a9-4bcb-b1e6-1ed8c3000393",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = \"This was the configuration used to initialize the model and load the data:\\n\\n\"\n",
    "md_text += \"| Parameter | Value |\\n\"\n",
    "md_text += \"| :--- | :--- |\\n\"\n",
    "\n",
    "for k, v in config.items():\n",
    "    display_key = k.replace(\"_\", \" \").title()\n",
    "    md_text += f\"| {display_key} | {v} |\\n\"\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551d818-fbd2-4686-8d29-0d0147cf00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dict_to_md(d, level=0):\n",
    "    lines = []\n",
    "    for k, v in d.items():\n",
    "        indent = \"  \" * level\n",
    "        if isinstance(v, dict) and v.get(\"min\") or v.get(\"max\"):\n",
    "            lines.append(f\"{indent}* **{k.capitalize()}**: From {v['min']:.4f} to {v['max']:.4f}\")\n",
    "        elif isinstance(v, dict):\n",
    "            lines.append(f\"{indent}* **{k.capitalize()}**:\")\n",
    "            lines.extend(format_dict_to_md(v, level + 1))\n",
    "        else:\n",
    "            lines.append(f\"{indent}* **{k}**: {v}\")\n",
    "    return lines\n",
    "\n",
    "md_text = \"The input data was then normalized between 0 and 1 based on those ranges:\\n\\n\"\n",
    "md_text += \"\\n\".join(format_dict_to_md(min_max_yaml))\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9301fe-447b-424a-8ecc-1efb2ffb7fc3",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "md_text = \"# Evaluation\\n\"\n",
    "md_text += \"## Loss Graphs\\n\"\n",
    "md_text += f\"The following figure shows the training, validation and test loss over the {num_epochs} epochs the model was trained on.\\n\\n\"\n",
    "md_text += \"![Train and test losses](losses.png)\\n\\n\"\n",
    "md_text += f\"The best losses archieved while training where {best_train_loss:.4g} on the training data, \"\n",
    "md_text += f\"{best_test_loss:.4g} on the test data and {best_val_loss:.4g} on the validation data.\\n\\n\"\n",
    "md_text += \"## Performance Metrics\\n\"\n",
    "md_text += \"The table below summarizes the error metrics for the velocity components u and v across all data splits.\\n\\n\"\n",
    "md_text += \"| Metric | Field | Training | Test | Validation |\\n\"\n",
    "md_text += \"| :--- | :--- | :--- | :--- | :--- |\\n\"\n",
    "md_text += f\"| **Mean absolute error** | u | {mae_u_train:.3g} | {mae_u_test:.3g} | {mae_u_val:.3g} |\\n\"\n",
    "md_text += f\"| | v | {mae_v_train:.3g} | {mae_v_test:.3g} | {mae_v_val:.3g} |\\n\"\n",
    "md_text += f\"| **Root mean square error** | u | {rmse_u_train:.3g} | {rmse_u_test:.3g} | {rmse_u_val:.3g} |\\n\"\n",
    "md_text += f\"| | v | {rmse_v_train:.3g} | {rmse_v_test:.3g} | {rmse_v_val:.3g} |\\n\"\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d7bbc-92d2-4d30-bc8b-57c397b8fac2",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "## Interpolation\n",
    "\n",
    "Sample data point predictions and comparisons to their labels (and visualization of vector fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03aadded-247b-4d68-a9ce-16f1a4d5f16b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/bene/CLionProjects/numsim/resources/plots/interpolation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m plot_dir \u001b[38;5;241m=\u001b[39m submission_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplots\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterpolation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m md_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m plot \u001b[38;5;129;01min\u001b[39;00m \u001b[43mplot_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m plot\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m     10\u001b[0m         flow_value \u001b[38;5;241m=\u001b[39m plot\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib64/python3.13/pathlib/_local.py:575\u001b[0m, in \u001b[0;36mPath.iterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yield path objects of the directory contents.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03mThe children are yielded in arbitrary order, and the\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03mspecial entries '.' and '..' are not included.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    574\u001b[0m root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m scandir_it:\n\u001b[1;32m    576\u001b[0m     paths \u001b[38;5;241m=\u001b[39m [entry\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m scandir_it]\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m root_dir \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/bene/CLionProjects/numsim/resources/plots/interpolation'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "submission_dir = Path(globals()['_dh'][0])\n",
    "\n",
    "plot_dir = submission_dir / \"plots\" / \"interpolation\"\n",
    "\n",
    "md_text = \"\"\n",
    "\n",
    "error_plots = []\n",
    "quiver_plots = []\n",
    "prediction_plots = []\n",
    "\n",
    "for plot in plot_dir.iterdir():\n",
    "    if plot.is_file():\n",
    "        if plot.name.startswith(\"error\"):\n",
    "            error_plots.append(plot)\n",
    "        elif plot.name.endswith(\"quiver.png\"):\n",
    "            quiver_plots.append(plot)\n",
    "        elif plot.name.startswith(\"prediction\"):\n",
    "            prediction_plots.append(plot)\n",
    "\n",
    "for pred, quiver, error in zip(prediction_plots, quiver_plots, error_plots):\n",
    "    flow_value = pred.name.split(\"_\")[-1].split(\".png\")[0]\n",
    "    md_text += f\"![{flow_value} Quiver](plots/interpolation/{quiver.name})\\n\\n\"\n",
    "    md_text += f\"![{flow_value} Prediction](plots/interpolation/{pred.name})\\n\\n\"\n",
    "    md_text += f\"![{flow_value} Error](plots/interpolation/{error.name})\\n\\n\"\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093ed2c-7b8d-4961-a519-9dad690c2757",
   "metadata": {},
   "source": [
    "## Extrapolation\n",
    "\n",
    "To see how well the model generalizes, the following section should contain three out-of-distribution test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f82b5-969d-43a1-a00a-eba3da1d8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "submission_dir = Path(globals()['_dh'][0])\n",
    "\n",
    "plot_dir = submission_dir / \"plots\" / \"extrapolation\"\n",
    "\n",
    "md_text = \"\"\n",
    "\n",
    "error_plots = []\n",
    "quiver_plots = []\n",
    "prediction_plots = []\n",
    "\n",
    "for plot in plot_dir.iterdir():\n",
    "    if plot.is_file():\n",
    "        if plot.name.startswith(\"error\"):\n",
    "            error_plots.append(plot)\n",
    "        if plot.name.endswith(\"quiver.png\"):\n",
    "            quiver_plots.append(plot)\n",
    "        elif plot.name.startswith(\"prediction\"):\n",
    "            prediction_plots.append(plot)\n",
    "\n",
    "for pred, quiver in zip(prediction_plots, quiver_plots):\n",
    "    flow_value = pred.name.split(\"_\")[-1].split(\".png\")[0]\n",
    "    md_text += f\"![{flow_value} Quiver](plots/extrapolation/{quiver.name})\\n\\n\"\n",
    "    md_text += f\"![{flow_value} Prediction](plots/extrapolation/{pred.name})\\n\\n\"\n",
    "\n",
    "display(Markdown(md_text))"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Julian Schmoll, Fabio Tucciarone, Benedikt RÃ¶sch"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "title": "Model Evaluation"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
